<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"><title>【机器学习】入门ML？跟着做这几个实验足矣！（二） | 泷汐の精神时光屋</title><meta name="keywords" content="机器学习"><meta name="author" content="TideDra,GearyZhang@outlook.com"><meta name="copyright" content="TideDra"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="随机森林 本课程需要使用的module: os, numpy, pandas, tensorflow(2.0.0及以上), matplotlib, sklearn, graphviz, pydotplus, skimage, opencv, seaborn. 目录 0. 课程摘要 1. 决策树 2. 分类决策树 3. 回归决策树 4. 本课任务介绍 - 4.1 MNIST介绍 - 4.2 数据的预">
<meta property="og:type" content="article">
<meta property="og:title" content="【机器学习】入门ML？跟着做这几个实验足矣！（二）">
<meta property="og:url" content="https://tidedra.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ML-exp2/index.html">
<meta property="og:site_name" content="泷汐の精神时光屋">
<meta property="og:description" content="随机森林 本课程需要使用的module: os, numpy, pandas, tensorflow(2.0.0及以上), matplotlib, sklearn, graphviz, pydotplus, skimage, opencv, seaborn. 目录 0. 课程摘要 1. 决策树 2. 分类决策树 3. 回归决策树 4. 本课任务介绍 - 4.1 MNIST介绍 - 4.2 数据的预">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/ML_exp1_cover.jpg">
<meta property="article:published_time" content="2022-03-29T16:59:36.000Z">
<meta property="article:modified_time" content="2022-03-30T02:58:06.913Z">
<meta property="article:author" content="TideDra">
<meta property="article:tag" content="机器学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/ML_exp1_cover.jpg"><link rel="shortcut icon" href="/img/business-man.png"><link rel="canonical" href="https://tidedra.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ML-exp2/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="google-site-verification" content="ev-WLSJNE26pCrlvY2Pg6U4IEX9_RPuCr1PkKJ5oewo"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6/css/all.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload="this.media='all'"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: {"appId":"S2H9LOYZXK","apiKey":"afe57ba6d261bf3d2627d49ad352458c","indexName":"MyBlog","hits":{"per_page":6},"languages":{"input_placeholder":"搜索文章","hits_empty":"找不到您查询的内容：${query}","hits_stats":"找到 ${hits} 条结果，用时 ${time} 毫秒"}},
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: {"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#1f1f1f","position":"bottom-center"},
  source: {
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/flickr-justified-gallery@2/dist/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '【机器学习】入门ML？跟着做这几个实验足矣！（二）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2022-03-30 10:58:06'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 6.1.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="https://img.zsaqwq.com/images/2022/03/26/girl.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data is-center"><div class="data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div><div class="data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a></div><div class="data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link"><i class="fa-fw fa-solid fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fa-solid fa-comments"></i><span> 说说</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/ML_exp1_cover.jpg')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">泷汐の精神时光屋</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 归档</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link"><i class="fa-fw fa-solid fa-link"></i><span> 链接</span></a></div><div class="menus_item"><a class="site-page" href="/artitalk/"><i class="fa-fw fa-solid fa-comments"></i><span> 说说</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【机器学习】入门ML？跟着做这几个实验足矣！（二）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2022-03-29T16:59:36.000Z" title="发表于 2022-03-30 00:59:36">2022-03-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2022-03-30T02:58:06.913Z" title="更新于 2022-03-30 10:58:06">2022-03-30</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="【机器学习】入门ML？跟着做这几个实验足矣！（二）"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1><center><font size=10>随机森林</font></center></h1>
<h2 id="本课程需要使用的module-os-numpy-pandas-tensorflow-2-0-0及以上-matplotlib-sklearn-graphviz-pydotplus-skimage-opencv-seaborn">本课程需要使用的module: os, numpy, pandas, tensorflow(2.0.0及以上), matplotlib, sklearn, graphviz, pydotplus, skimage, opencv, seaborn.</h2>
<h1><span id='content'>目录</span></h1>
<h2 id="0-课程摘要"><a href="#0">0. 课程摘要</a></h2>
<h2 id="1-决策树"><a href="#1">1. 决策树</a></h2>
<h2 id="2-分类决策树"><a href="#2">2. 分类决策树</a></h2>
<h2 id="3-回归决策树"><a href="#3">3. 回归决策树</a></h2>
<h2 id="4-本课任务介绍"><a href="#4">4. 本课任务介绍</a></h2>
<h3 id="4-1-MNIST介绍"><a href="#4.1">- 4.1 MNIST介绍</a></h3>
<h3 id="4-2-数据的预处理"><a href="#4.2">- 4.2 数据的预处理</a></h3>
<h2 id="5-随机森林"><a href="#5">5. 随机森林</a></h2>
<h3 id="5-1-分类式随机森林"><a href="#5.1">- 5.1 分类式随机森林</a></h3>
<h3 id="5-2-回归式随机森林"><a href="#5.2">- 5.2 回归式随机森林</a></h3>
<h3 id="5-3-预测错误展示"><a href="#5.3">- 5.3 预测错误展示</a></h3>
<h2 id="6-非数据库图片测试"><a href="#6">6. 非数据库图片测试</a></h2>
<h2 id="7-总结"><a href="#7">7. 总结</a></h2>
<h1>Homework</h1>
<h2 id="作业1"><a href="#HW1">作业1</a></h2>
<h2 id="作业2"><a href="#HW2">作业2</a></h2>
<h2 id="作业3"><a href="#HW3">作业3</a></h2>
<h2 id="作业4"><a href="#HW4">作业4</a></h2>
<h2 id="作业5"><a href="#HW5">作业5</a></h2>
<h1>加载library</h1>
<h2 id="首先让我们将需要的module准备好。">首先让我们将需要的module准备好。</h2>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">!pip install scikit-image</span><br><span class="line">!pip install pydotplus</span><br></pre></td></tr></table></figure>
<pre><code>Requirement already satisfied: scikit-image in d:\application\anaconda\lib\site-packages (0.18.3)
Requirement already satisfied: numpy&gt;=1.16.5 in d:\application\anaconda\lib\site-packages (from scikit-image) (1.20.3)
Requirement already satisfied: scipy&gt;=1.0.1 in d:\application\anaconda\lib\site-packages (from scikit-image) (1.7.1)
Requirement already satisfied: matplotlib!=3.0.0,&gt;=2.0.0 in d:\application\anaconda\lib\site-packages (from scikit-image) (3.4.3)
Requirement already satisfied: networkx&gt;=2.0 in d:\application\anaconda\lib\site-packages (from scikit-image) (2.6.3)
Requirement already satisfied: pillow!=7.1.0,!=7.1.1,&gt;=4.3.0 in d:\application\anaconda\lib\site-packages (from scikit-image) (8.4.0)
Requirement already satisfied: imageio&gt;=2.3.0 in d:\application\anaconda\lib\site-packages (from scikit-image) (2.9.0)
Requirement already satisfied: tifffile&gt;=2019.7.26 in d:\application\anaconda\lib\site-packages (from scikit-image) (2021.7.2)
Requirement already satisfied: PyWavelets&gt;=1.1.1 in d:\application\anaconda\lib\site-packages (from scikit-image) (1.1.1)
Requirement already satisfied: kiwisolver&gt;=1.0.1 in d:\application\anaconda\lib\site-packages (from matplotlib!=3.0.0,&gt;=2.0.0-&gt;scikit-image) (1.3.1)
Requirement already satisfied: cycler&gt;=0.10 in d:\application\anaconda\lib\site-packages (from matplotlib!=3.0.0,&gt;=2.0.0-&gt;scikit-image) (0.10.0)
Requirement already satisfied: python-dateutil&gt;=2.7 in d:\application\anaconda\lib\site-packages (from matplotlib!=3.0.0,&gt;=2.0.0-&gt;scikit-image) (2.8.2)
Requirement already satisfied: pyparsing&gt;=2.2.1 in d:\application\anaconda\lib\site-packages (from matplotlib!=3.0.0,&gt;=2.0.0-&gt;scikit-image) (3.0.4)
Requirement already satisfied: six in d:\application\anaconda\lib\site-packages (from cycler&gt;=0.10-&gt;matplotlib!=3.0.0,&gt;=2.0.0-&gt;scikit-image) (1.16.0)
Collecting pydotplus
  Downloading pydotplus-2.0.2.tar.gz (278 kB)
Requirement already satisfied: pyparsing&gt;=2.0.1 in d:\application\anaconda\lib\site-packages (from pydotplus) (3.0.4)
Building wheels for collected packages: pydotplus
  Building wheel for pydotplus (setup.py): started
  Building wheel for pydotplus (setup.py): finished with status 'done'
  Created wheel for pydotplus: filename=pydotplus-2.0.2-py3-none-any.whl size=24575 sha256=5077bd53ca5a3f6f7f24d96630ee00a36f705cdd2ceba0c43c4046b659ba42cd
  Stored in directory: c:\users\71852\appdata\local\pip\cache\wheels\89\e5\de\6966007cf223872eedfbebbe0e074534e72e9128c8fd4b55eb
Successfully built pydotplus
Installing collected packages: pydotplus
Successfully installed pydotplus-2.0.2
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf    <span class="comment">#tensorflow: conda install tensorflow</span></span><br><span class="line"><span class="keyword">import</span> graphviz    <span class="comment">#graphviz: conda install python-graphviz</span></span><br><span class="line"><span class="keyword">from</span> IPython.display <span class="keyword">import</span> Image <span class="comment">#图像处理及输出 conda install ipython</span></span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd    <span class="comment">#pandas: conda install pandas</span></span><br><span class="line"><span class="keyword">import</span> pydotplus    <span class="comment">#pydotplus: pip install pydotplus</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np    <span class="comment">#numpy: conda install numpy</span></span><br><span class="line"><span class="keyword">import</span> os <span class="comment">#读取文件路径module</span></span><br><span class="line"><span class="keyword">import</span> random <span class="comment">#随机数生成module</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt <span class="comment">#绘图module</span></span><br><span class="line"><span class="keyword">from</span> warnings <span class="keyword">import</span> simplefilter</span><br><span class="line"><span class="keyword">import</span> seaborn <span class="keyword">as</span> sns</span><br><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line">simplefilter(action=<span class="string">&#x27;ignore&#x27;</span>, category=FutureWarning)<span class="comment">#避免大量的FutureWarning</span></span><br></pre></td></tr></table></figure>
<h1><span id="0">0. 课程摘要</span></h1>
<p>前一部分的课程给大家介绍了分类和回归问题的处理方法，这一课给大家介绍一种既可以用于回归问题，也可以用于分类问题的算法：<strong>随机森林</strong>。</p>
<p>随机森林是一种灵活，易于使用的机器学习算法，即使没有超参数调整，也能在大多数情况下产生出色的结果。</p>
<p>本课内容包括随机森林的组成部分：决策树的原理和生成，随机森林的原理、生成。我们将使用随机森林模型解决一个有趣的问题：手写数字识别问题。</p>
<p><br/><strong>随机森林</strong>是由不同的<strong>决策树</strong>组成的，所以首先给大家介绍<strong>决策树</strong>。</p>
<h1><span id="1">1. 决策树</span></h1>
<p>决策树是一种二叉树。在计算机科学中，二叉树（英语：Binary tree）是每个节点最多只有两个分支（即不存在分支度大于2的节点）的树结构。通常分支被称作“左子树”或“右子树”。二叉树的分支具有左右次序，不能随意颠倒。</p>
<h3 id="树的相关知识：">树的相关知识：</h3>
<blockquote>
<ul>
<li>
<p>节点的度：一个节点含有的子树的个数称为该节点的度；</p>
</li>
<li>
<p>树的度：一棵树中，最大的节点度称为树的度；</p>
</li>
<li>
<p>叶节点或终端节点：度为零的节点；</p>
</li>
<li>
<p>父亲节点或父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点；</p>
</li>
<li>
<p>孩子节点或子节点：一个节点含有的子树的根节点称为该节点的子节点；</p>
</li>
<li>
<p>兄弟节点：具有相同父节点的节点互称为兄弟节点；</p>
</li>
<li>
<p>节点的层次：从根开始定义起，根为第1层，根的子节点为第2层，以此类推；</p>
</li>
<li>
<p>深度：对于任意节点n,n的深度为从根到n的唯一路径长，根的深度为0；</p>
</li>
<li>
<p>高度：对于任意节点n,n的高度为从n到一片树叶的最长路径长，所有树叶的高度为0；</p>
</li>
</ul>
</blockquote>
<h3 id="例：此处我们以iris-dataset的分类问题建立一个决策树。">例：此处我们以iris dataset的分类问题建立一个决策树。</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> load_iris <span class="comment">#鸢尾花数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> tree <span class="comment">#决策树module</span></span><br><span class="line"><span class="comment">#使用iris数据集</span></span><br><span class="line">iris = load_iris()</span><br><span class="line"></span><br><span class="line"><span class="comment">#样例：分类树</span></span><br><span class="line">clf = tree.DecisionTreeClassifier()</span><br><span class="line">clf = clf.fit(iris.data, iris.target)</span><br><span class="line">dot_data = tree.export_graphviz(clf, out_file=<span class="literal">None</span>, </span><br><span class="line">feature_names=iris.feature_names,  </span><br><span class="line">class_names=iris.target_names,  </span><br><span class="line">filled=<span class="literal">True</span>, rounded=<span class="literal">True</span>,  </span><br><span class="line">special_characters=<span class="literal">True</span>                                </span><br><span class="line">)</span><br><span class="line"></span><br><span class="line"><span class="comment">#作图</span></span><br><span class="line">graph = pydotplus.graph_from_dot_data(dot_data)</span><br><span class="line">img = Image(graph.create_png())</span><br><span class="line">graph.write_png(<span class="string">&quot;Example_1.png&quot;</span>)</span><br><span class="line"><span class="comment">#下面进行决策树图片的输出</span></span><br></pre></td></tr></table></figure>
<pre><code>True
</code></pre>
<img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/Example_1.png" style="zoom:65%" />
<br/><center><font size=5>Example 1: A decision tree for the iris dataset</font></center>
<p><br/><font size=4></p>
<pre><code>图注： 
- sample：该节点所包含的样本数量。
- value：该节点中样本对应的各类鸢尾花的数量，该list中第一个元素为山鸢尾数量，第二个为变色鸢尾数量，第三个为维吉尼亚鸢尾数量。
- class：该节点的输出（山鸢尾 (Setosa)、变色鸢尾 (Versicolour) 和维吉尼亚鸢尾 (Virginica)）
- gini：该节点的基尼指数。
- 颜色：该节点的输出。褐色为山鸢尾，绿色为变色鸢尾，紫色为维吉尼亚鸢尾。深浅度代表了所得结果的概率大小。

决策树以基尼指数(gini)为拓展分支的准则，在下面的内容里我们将介绍这一重要概念。
</code></pre>
</font>
<h1><span id="2">2. 分类决策树</span></h1>
<h4 id="分类树分析是当预计结果可能为离散类型（例如三个种类的花，输赢等）使用的概念。">分类树分析是当预计结果可能为离散类型（例如三个种类的花，输赢等）使用的概念。</h4>
<ul>
<li>
<p>特征和特征数值如何选取：</p>
<ul>
<li>
<p>基尼指数</p>
<ul>
<li>
<p>基尼指数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>i</mi><mi>n</mi><mi>i</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Gini(D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">ini</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span></span></span></span>表示集合<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span></span></span></span>不确定性，基尼指数<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>G</mi><mi>i</mi><mi>n</mi><mi>i</mi><mo stretchy="false">(</mo><mi>D</mi><mtext>，</mtext><mi>A</mi><mo>=</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">Gini(D，A=a)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">ini</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mord cjk_fallback">，</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">a</span><span class="mclose">)</span></span></span></span>表示集合D经<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>=</mo><mi>a</mi></mrow><annotation encoding="application/x-tex">A=a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span>分割后的不确定性(类似于熵)，</p>
</li>
<li>
<p>基尼指数越小，样本的不确定性越小。</p>
</li>
<li>
<p>基尼值是指从一个样本集中选择2个样本，这2个样本不属于同一类的概率：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>G</mi><mi>i</mi><mi>n</mi><mi>i</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>p</mi><mi>k</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn><mo>−</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><mi>K</mi></munderover><msubsup><mi>p</mi><mi>k</mi><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">Gini(D)=\sum^K_{k=1}p_k(1-p_k)=1-\sum^K_{k=1}p_k^2 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathnormal">G</span><span class="mord mathnormal">ini</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3361em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em;"><span style="top:-1.8479em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.07153em;">K</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">p</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-2.453em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.03148em;">k</span></span></span><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.247em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow></mrow><annotation encoding="application/x-tex">


</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"></span></span></span></p>
</li>
<li>
<p>可以看出基尼值越小说明该数据集中不同类的数据越少，即数据集纯度越高。</p>
</li>
<li>
<p>在所有可能的特征A以及该特征所有的可能取值<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span>中，选择基尼指数最小的特征及其对应的取值作为最优特征和最优切分点。</p>
<p>当特征A所对应的值为连续值时，对样本的特征A的值<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">a</span></span></span></span>进行升序排序，从小到大取相邻两个值的平均值作为阈值进行划分，在所有切分点中，基尼指数最小的即为最优切分点。</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h3 id="例：以体重与患心脏病情况的关系为例来说明如何生成分类二叉树。">例：以体重与患心脏病情况的关系为例来说明如何生成分类二叉树。</h3>
<p>Source: <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=7VeUPuFGJHk&amp;t=779s">https://www.youtube.com/watch?v=7VeUPuFGJHk&amp;t=779s</a></p>
<p><br/><img title="" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/classifier_tree_1.png" alt="" style="zoom:45%"><br>
<br/><center><font size=3 color="blue">这是该问题的一个简单的数据集。</font></center></p>
<p><br/><img title="" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/classifier_tree_2.png" alt="" style="zoom:45%"><br>
<br/><center><font size=3 color="blue">第一步，将样本按照连续型特征的大小进行排序。</font></center></p>
<p><br/><img title="" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/classifier_tree_3.jpg" alt="" style="zoom:35%"><br>
<br/><center><font size=3 color="blue">第二步，计算两相邻样本该特征的平均值，作为备选的切分点。</font></center></p>
<p><br/><img title="" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/classifier_tree_4.jpg" alt="" style="zoom:40%"><br>
<br/><center><font size=2 color="blue">例：计算基尼指数。</font></center><br>
<br/><img title="" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/classifier_tree_5.jpg" alt="" style="zoom:40%"><br>
<br/><center><font size=3 color="blue">第三步，计算每个切分点对应的基尼指数。</font></center></p>
<br/>
<p><img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/regression_tree_3.png" alt=""><br/><img title="" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/regression_tree_3.1.jpeg" alt="" style="zoom:30%"><br>
<br/><center><font size=3 color="blue">寻找函数最小值所对应的切分点特征及其取值，即为最佳切分点。</font></center></p>
<p><br/><img title="" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/classifier_tree_6.jpg" alt="" style="zoom:70%"><br>
<br/><center><font size=3 color="blue">第四步，选取最小基尼指数对应的切分点作为最终切分点。</font></center></p>
<p><br/><center><font size=3 color="blue">第五步，对每个子节点循环第二步～第四步直至无法再分。</font></center></p>
<h3 id="span-id-HW1-作业1-span-："><span id='HW1'>作业1</span>：</h3>
<p>写一个函数来计算基尼指数。<strong>（请在编写代码部分完成作业1）</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">######Mission 1: Compute Gini coefficient.######</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#问题描述: 现有一贷款申请样本数据表，</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#共15组样本，4个特征，</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#特征的取值是离散的，</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#输出为申请贷款结果class，</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#现需要根据样本数据表计算各种分割方式的基尼指数。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#####################################</span></span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#此处为讲解基尼指数的计算方法和过程加载贷款申请样本数据表</span></span><br><span class="line"><span class="comment">#读取数据集</span></span><br><span class="line">dataset = pd.read_csv(<span class="string">r&quot;datasetForGini.csv&quot;</span>)</span><br><span class="line"><span class="comment">#输出数据集</span></span><br><span class="line"><span class="built_in">print</span>(dataset,<span class="string">&quot;\n&quot;</span>)</span><br></pre></td></tr></table></figure>
<pre><code>      age work house     credit   class
0   youth   no    no     common  refuse
1   youth   no    no       good  refuse
2   youth  yes    no       good   agree
3   youth  yes   yes     common   agree
4   youth   no    no     common  refuse
5     mid   no    no     common  refuse
6     mid   no    no       good  refuse
7     mid  yes   yes       good   agree
8     mid   no   yes  excellent   agree
9     mid   no   yes  excellent   agree
10  elder   no   yes  excellent   agree
11  elder   no   yes       good   agree
12  elder  yes    no       good   agree
13  elder  yes    no  excellent   agree
14  elder   no    no     common  refuse 
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#获得特征种类</span></span><br><span class="line">features = []</span><br><span class="line"><span class="comment">#了解特征详情</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> dataset.columns:</span><br><span class="line">    features.append(i)</span><br><span class="line"></span><br><span class="line">features.pop()<span class="comment">#不要最后一列的标签（指class：agree/refuse）</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;特征有:&quot;</span>,features)</span><br></pre></td></tr></table></figure>
<pre><code>特征有: ['age', 'work', 'house', 'credit']
</code></pre>
<p><strong>编写代码部分：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#设计Gini函数求基尼指数，其中参数dataset是数据集，feature为所选特征，value为所选特征的取值(当然也可以不使用这里给出的参数)。</span></span><br><span class="line"><span class="comment">#这个函数返回对应特征取值得到的基尼指数(保留两位小数)。</span></span><br><span class="line"><span class="comment">#提示：根据之前给出的计算公式设计此函数</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">Gini</span>(<span class="params">dataset,feature,value</span>):</span><br><span class="line">    r_num=<span class="number">0</span></span><br><span class="line">    a_num=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> ind, i <span class="keyword">in</span> <span class="built_in">enumerate</span>(dataset[feature]):</span><br><span class="line">        <span class="keyword">if</span> i == value:</span><br><span class="line">            <span class="keyword">if</span> dataset[<span class="string">&#x27;class&#x27;</span>][ind]==<span class="string">&#x27;refuse&#x27;</span>:</span><br><span class="line">                r_num+=<span class="number">1</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                a_num+=<span class="number">1</span></span><br><span class="line">    total_num = r_num+a_num</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">round</span>(<span class="number">1</span>-(r_num/total_num)*(r_num/total_num)-(a_num/total_num)*(a_num/total_num), <span class="number">2</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#进行基尼指数输出</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择的特征是age，取值是youth, 基尼指数为： &quot;</span>,Gini(dataset,<span class="string">&#x27;age&#x27;</span>,<span class="string">&#x27;youth&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择的特征是age，取值是elder, 基尼指数为： &quot;</span>,Gini(dataset,<span class="string">&#x27;age&#x27;</span>,<span class="string">&#x27;elder&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择的特征是work，取值是yes, 基尼指数为： &quot;</span>,Gini(dataset,<span class="string">&#x27;work&#x27;</span>,<span class="string">&#x27;yes&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择的特征是house，取值是no, 基尼指数为： &quot;</span>,Gini(dataset,<span class="string">&#x27;house&#x27;</span>,<span class="string">&#x27;no&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择的特征是house，取值是yes, 基尼指数为： &quot;</span>,Gini(dataset,<span class="string">&#x27;house&#x27;</span>,<span class="string">&#x27;yes&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择的特征是credit，取值是common, 基尼指数为： &quot;</span>,Gini(dataset,<span class="string">&#x27;credit&#x27;</span>,<span class="string">&#x27;common&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;选择的特征是credit，取值是good, 基尼指数为： &quot;</span>,Gini(dataset,<span class="string">&#x27;credit&#x27;</span>,<span class="string">&#x27;good&#x27;</span>))</span><br></pre></td></tr></table></figure>
<pre><code>选择的特征是age，取值是youth, 基尼指数为：  0.48
选择的特征是age，取值是elder, 基尼指数为：  0.32
选择的特征是work，取值是yes, 基尼指数为：  0.0
选择的特征是house，取值是no, 基尼指数为：  0.44
选择的特征是house，取值是yes, 基尼指数为：  0.0
选择的特征是credit，取值是common, 基尼指数为：  0.32
选择的特征是credit，取值是good, 基尼指数为：  0.44
</code></pre>
<p><strong>决策树的输出值为树叶上大多数样本所属的类别：</strong></p>
<p>如上图例1所示，每个节点都有一个class数据成员。</p>
<p>譬如训练样本包括A,B,C三个类别，某一树叶上对应8个A类样本，2个B类样本，1个C类样本，那么这个树叶的输出则是A类别。</p>
<p><strong>附：其它选择特征的方式</strong>：</p>
<p><strong>信息熵</strong>(information entropy)是度量样本集合纯度的一种常用指标。</p>
<p>我们可以通过与之相关的<strong>信息增益</strong>选取特征。</p>
<p>（简单了解即可）</p>
<h1><span id="3">3. 回归决策树</span></h1>
<p>回归决策树是可以用于回归的决策树模型，一个回归树对应着输入空间（即特征空间）的一个划分以及在划分单元上的输出值。</p>
<p>在生成和输出过程中，回归决策树和分类决策树主要有两点不同：</p>
<ul>
<li>特征选择</li>
</ul>
<p>假设X和Y分别为输入和输出变量，并且Y是连续变量，给定训练数据集为<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo>=</mo><mrow><mo fence="true">{</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><mo stretchy="false">(</mo><msub><mi>x</mi><mi>N</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>N</mi></msub><mo stretchy="false">)</mo><mo fence="true">}</mo></mrow></mrow><annotation encoding="application/x-tex">D=\left \{ (x_1,y_1 ),(x_2,y_2 ),...,(x_N,y_N) \right \}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em;"></span><span class="mord mathnormal" style="margin-right:0.02778em;">D</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;">{</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">...</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose delimcenter" style="top:0em;">}</span></span></span></span></span>，其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathsize="0.9em"><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><mo stretchy="false">(</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo stretchy="false">(</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msubsup><mo separator="true">,</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo stretchy="false">(</mo><mn>2</mn><mo stretchy="false">)</mo></mrow></msubsup><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msubsup><mi>x</mi><mi>i</mi><mrow><mo stretchy="false">(</mo><mi>n</mi><mo stretchy="false">)</mo></mrow></msubsup><mo stretchy="false">)</mo></mstyle></mrow><annotation encoding="application/x-tex">\small x_i=(x_{i}^{(1)},x_{i}^{(2)},...,x_{i}^{(n)})</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5225em;vertical-align:-0.135em;"></span><span class="mord sizing reset-size6 size5"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2897em;"><span style="top:-2.45em;margin-left:0em;margin-right:0.0556em;"><span class="pstrut" style="height:2.6em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel sizing reset-size6 size5">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1397em;vertical-align:-0.2294em;"></span><span class="mopen sizing reset-size6 size5">(</span><span class="mord sizing reset-size6 size5"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0115em;"><span style="top:-2.3451em;margin-left:0em;margin-right:0.0556em;"><span class="pstrut" style="height:2.6em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.1115em;margin-right:0.0556em;"><span class="pstrut" style="height:2.6em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2549em;"><span></span></span></span></span></span></span><span class="mpunct sizing reset-size6 size5">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord sizing reset-size6 size5"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0115em;"><span style="top:-2.3451em;margin-left:0em;margin-right:0.0556em;"><span class="pstrut" style="height:2.6em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.1115em;margin-right:0.0556em;"><span class="pstrut" style="height:2.6em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mtight">2</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2549em;"><span></span></span></span></span></span></span><span class="mpunct sizing reset-size6 size5">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord sizing reset-size6 size5">...</span><span class="mpunct sizing reset-size6 size5">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord sizing reset-size6 size5"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.0115em;"><span style="top:-2.3451em;margin-left:0em;margin-right:0.0556em;"><span class="pstrut" style="height:2.6em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span style="top:-3.1115em;margin-right:0.0556em;"><span class="pstrut" style="height:2.6em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight">n</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2549em;"><span></span></span></span></span></span></span><span class="mclose sizing reset-size6 size5">)</span></span></span></span>为输入实例(特征向量)，n为特征个数，i=1,2,…,N, N为样本容量。</p>
<p>特征<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.854em;vertical-align:-0.1944em;"></span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span></span></span></span>和特征取值<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em;"></span><span class="mord mathnormal">s</span></span></span></span>：</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>R</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mi>x</mi><mi mathvariant="normal">∣</mi><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msup><mo>&lt;</mo><mo>=</mo><mi>s</mi></mrow><mspace linebreak="newline"></mspace><msub><mi>R</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi>s</mi><mo stretchy="false">)</mo><mo>=</mo><mrow><mi>x</mi><mi mathvariant="normal">∣</mi><msup><mi>x</mi><mrow><mo stretchy="false">(</mo><mi>j</mi><mo stretchy="false">)</mo></mrow></msup><mo>&gt;</mo><mi>s</mi></mrow><mspace linebreak="newline"></mspace><mi>m</mi><mi>i</mi><msub><mi>n</mi><mrow><mi>j</mi><mo separator="true">,</mo><mi>s</mi></mrow></msub><mrow><mo stretchy="false">[</mo><munder><mo>∑</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><msub><mi>R</mi><mn>1</mn></msub><mrow><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></mrow></munder><mo stretchy="false">(</mo><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><msub><mi>c</mi><mn>1</mn></msub><mo>^</mo></mover></mrow><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo>+</mo><munder><mo>∑</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><msub><mi>R</mi><mn>2</mn></msub><mrow><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></mrow></munder><mo stretchy="false">(</mo><mrow><msub><mi>y</mi><mi>i</mi></msub><mo>−</mo><mover accent="true"><msub><mi>c</mi><mn>2</mn></msub><mo>^</mo></mover></mrow><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mo stretchy="false">]</mo></mrow></mrow><annotation encoding="application/x-tex">R_1(j,s)={x|x^{(j)}&lt;=s}\\
R_2(j,s)={x|x^{(j)}&gt;s}\\
min_{j,s}{[\sum_{x_i\in R_1{(j,s)}}({y_i-\hat{c_1}})^2+\sum_{x_i\in R_2{(j,s)}}({y_i-\hat{c_2}})^2]} 
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&lt;=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">s</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:-0.0077em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">s</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">&gt;</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathnormal">s</span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:2.566em;vertical-align:-1.516em;"></span><span class="mord mathnormal">mi</span><span class="mord"><span class="mord mathnormal">n</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">s</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2861em;"><span></span></span></span></span></span></span><span class="mord"><span class="mopen">[</span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.809em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0077em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em;"><span style="top:-1.809em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3281em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:-0.0077em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span style="top:-3.05em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.516em;"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:-0.0359em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span></span></p>
<p>其中<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathsize="0.9em"><mover accent="true"><msub><mi>c</mi><mn>1</mn></msub><mo>^</mo></mover><mo>=</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>1</mn></msub></mfrac><msub><mo>∑</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><msub><mi>R</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></msub><msub><mi>y</mi><mi>i</mi></msub></mstyle></mrow><annotation encoding="application/x-tex">\small \hat{c_1}=\frac{1}{N_1}\sum_{x_i\in R_1(j,s)}y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76em;vertical-align:-0.135em;"></span><span class="mord accent sizing reset-size6 size5"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.9em;"><span class="pstrut" style="height:2.9em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2796em;"><span style="top:-2.45em;margin-left:0em;margin-right:0.0556em;"><span class="pstrut" style="height:2.6em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span style="top:-2.9em;"><span class="pstrut" style="height:2.9em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel sizing reset-size6 size5">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1763em;vertical-align:-0.435em;"></span><span class="mord sizing reset-size6 size5"><span class="mopen nulldelimiter sizing reset-size5 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8236em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.337em;"><span style="top:-2.337em;margin-left:-0.109em;margin-right:0.0833em;"><span class="pstrut" style="height:2.537em;"></span><span class="sizing reset-size2 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4783em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size5 size6"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop sizing reset-size6 size5"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1833em;"><span style="top:-2.2833em;margin-left:0em;margin-right:0.0556em;"><span class="pstrut" style="height:2.6em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.0833em;"><span class="pstrut" style="height:2.5496em;"></span><span class="sizing reset-size2 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2048em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.337em;"><span style="top:-2.337em;margin-left:-0.0077em;margin-right:0.0833em;"><span class="pstrut" style="height:2.537em;"></span><span class="sizing reset-size2 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4833em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord sizing reset-size6 size5"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2897em;"><span style="top:-2.45em;margin-left:-0.0359em;margin-right:0.0556em;"><span class="pstrut" style="height:2.6em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>，   <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle mathsize="0.9em"><mover accent="true"><msub><mi>c</mi><mn>2</mn></msub><mo>^</mo></mover><mo>=</mo><mfrac><mn>1</mn><msub><mi>N</mi><mn>2</mn></msub></mfrac><msub><mo>∑</mo><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><msub><mi>R</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi>s</mi><mo stretchy="false">)</mo></mrow></msub><msub><mi>y</mi><mi>i</mi></msub></mstyle></mrow><annotation encoding="application/x-tex">\small \hat{c_2}=\frac{1}{N_2}\sum_{x_i\in R_2(j,s)}y_i</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.76em;vertical-align:-0.135em;"></span><span class="mord accent sizing reset-size6 size5"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.6944em;"><span style="top:-2.9em;"><span class="pstrut" style="height:2.9em;"></span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2796em;"><span style="top:-2.45em;margin-left:0em;margin-right:0.0556em;"><span class="pstrut" style="height:2.6em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span><span style="top:-2.9em;"><span class="pstrut" style="height:2.9em;"></span><span class="accent-body" style="left:-0.25em;"><span class="mord">^</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel sizing reset-size6 size5">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:1.1763em;vertical-align:-0.435em;"></span><span class="mord sizing reset-size6 size5"><span class="mopen nulldelimiter sizing reset-size5 size6"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.8236em;"><span style="top:-2.655em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.337em;"><span style="top:-2.337em;margin-left:-0.109em;margin-right:0.0833em;"><span class="pstrut" style="height:2.537em;"></span><span class="sizing reset-size2 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2em;"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.394em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight"><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4783em;"><span></span></span></span></span></span><span class="mclose nulldelimiter sizing reset-size5 size6"></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mop sizing reset-size6 size5"><span class="mop op-symbol small-op" style="position:relative;top:0em;">∑</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1833em;"><span style="top:-2.2833em;margin-left:0em;margin-right:0.0556em;"><span class="pstrut" style="height:2.6em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3448em;margin-left:0em;margin-right:0.0833em;"><span class="pstrut" style="height:2.5496em;"></span><span class="sizing reset-size2 size1 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2048em;"><span></span></span></span></span></span></span><span class="mrel mtight">∈</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.337em;"><span style="top:-2.337em;margin-left:-0.0077em;margin-right:0.0833em;"><span class="pstrut" style="height:2.537em;"></span><span class="sizing reset-size2 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.2em;"><span></span></span></span></span></span></span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:0.05724em;">j</span><span class="mpunct mtight">,</span><span class="mord mathnormal mtight">s</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.4833em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord sizing reset-size6 size5"><span class="mord mathnormal" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2897em;"><span style="top:-2.45em;margin-left:-0.0359em;margin-right:0.0556em;"><span class="pstrut" style="height:2.6em;"></span><span class="sizing reset-size5 size2 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>。</p>
<p>找到最优的切分点<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>j</mi><mo separator="true">,</mo><mi>s</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(j,s)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.05724em;">j</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">s</span><span class="mclose">)</span></span></span></span>后，依次将输入空间划分为两个区域，接着对每个区域重复上述划分过程，直到满足停止条件为止。这样就生成了一棵回归树，这样的回归树通常称为最小二乘回归树。</p>
<ul>
<li>输出值</li>
</ul>
<p>输出值为单元内每个样本点的值的均值。</p>
<h3 id="例：药物剂量">例：药物剂量</h3>
<p>Source: <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=g9c66TUylZ4&amp;t=769s">https://www.youtube.com/watch?v=g9c66TUylZ4&amp;t=769s</a></p>
<h4 id="此视频中的问题是一个单特征问题（Drug-Effective-Drug-Dosage）。">此视频中的问题是一个单特征问题（Drug-Effective - Drug Dosage）。</h4>
<p><br/><img title="" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/regression_tree_1.1.png" alt="" style="zoom:30%"><br>
<br/><center><font size=3 color="blue">这是本例所使用的数据集，</font></center></p>
<p><br/><img title="" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/regression_tree_1.2.png" alt="" style="zoom:60%"><br>
<br/><center><font size=3 color="blue">这是根据数据集画出的散点图，使用它来进行讲解。</font></center></p>
<p><br/><img title="" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/regression_tree_2.1.jpg" alt="" style="zoom:40%"><br>
<br/><center><font size=3 color="blue">首先我们选取切分点进行切分，将所有数据点根据切分条件（红线）分入两个子集<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>s</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">s_1,s_2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord"><span class="mord mathnormal">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span>（图左侧），</font></center><br>
<br/><center><font size=3 color="blue">其次我们计算每个样本点的预测值与所属子集的所有样本点观测值的平均值的平方差（图右侧），</font></center><br>
<br/><center><font size=3 color="blue">将所有平方差作求和得到最终的目标函数，是一个关于切分点取值的函数。</font></center></p>
<p><br/><img title="" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/regression_tree_2.2.jpg" alt="" style="zoom:40%"><br>
<br/><center><font size=3 color="blue">之后我们更换切分点取值，再进行一次上述操作</font></center></p>
<h1><span id="4">4. 本课任务介绍：手写数字识别问题</span></h1>
<p>输入为手写数字数据集，样本为三维数组<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>∈</mo><msup><mi>R</mi><mrow><mi>N</mi><mo>×</mo><msub><mi>s</mi><mn>1</mn></msub><mo>×</mo><msub><mi>s</mi><mn>2</mn></msub></mrow></msup></mrow><annotation encoding="application/x-tex">x_i\in R^ {N\times s_1\times s_2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6891em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">∈</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.8413em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8413em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em;">N</span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mbin mtight">×</span><span class="mord mtight"><span class="mord mathnormal mtight">s</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3173em;"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span>，每个样本对应0~9中的一个数字。</p>
<p><strong>作为10类别分类问题，输出为0~9。</strong></p>
<p><strong>也可以作为回归问题处理。</strong></p>
<h2 id="span-id-4-1-4-1-MNIST介绍-span"><span id="4.1">4.1 MNIST介绍</span></h2>
<p>MNIST数据集(Mixed National Institute of Standards and Technology database)是美国国家标准与技术研究院收集整理的大型手写数字数据库。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">sns.set_style(<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#加载MNIST数据集</span></span><br><span class="line">hand_written_digits = <span class="built_in">list</span>(tf.keras.datasets.mnist.load_data()[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#取前12000个样本</span></span><br><span class="line"><span class="comment">#获得样本X</span></span><br><span class="line">hand_written_digits[<span class="number">0</span>]=hand_written_digits[<span class="number">0</span>][<span class="number">0</span>:<span class="number">12000</span>]</span><br><span class="line"><span class="comment">#获得标签y</span></span><br><span class="line">hand_written_digits[<span class="number">1</span>]=hand_written_digits[<span class="number">1</span>][<span class="number">0</span>:<span class="number">12000</span>]</span><br></pre></td></tr></table></figure>
<pre><code>Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz
11493376/11490434 [==============================] - 2s 0us/step
11501568/11490434 [==============================] - 2s 0us/step
</code></pre>
<h3 id="span-id-HW2-作业2：-span"><span id='HW2'>作业2：</span></h3>
<p>补充下一个代码块使其能够按顺序展示0～9，每个标签各一个样本。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#添加代码使mnist_example从hand_written_digits处获得样本。</span></span><br><span class="line">mnist_example=[]</span><br><span class="line">i=<span class="number">0</span></span><br><span class="line">ind=<span class="number">0</span></span><br><span class="line"><span class="keyword">while</span> i&lt;<span class="number">10</span>:</span><br><span class="line">    <span class="keyword">if</span> hand_written_digits[<span class="number">1</span>][ind]==i:</span><br><span class="line">        mnist_example.append([hand_written_digits[<span class="number">0</span>][ind],i])</span><br><span class="line">        i+=<span class="number">1</span></span><br><span class="line">    ind+=<span class="number">1</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;MNIST样例&quot;</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">8</span>))            </span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">1</span>,<span class="built_in">len</span>(mnist_example)+<span class="number">1</span>):</span><br><span class="line">    ax=plt.subplot(<span class="number">2</span>,<span class="number">5</span>,i)</span><br><span class="line">    ax.matshow(mnist_example[i-<span class="number">1</span>][<span class="number">0</span>])</span><br><span class="line">    ax.set_title(<span class="string">&quot;A sample of %d\n&quot;</span>%(i-<span class="number">1</span>))</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>MNIST样例
</code></pre>
<p><img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/RandomForest(ForExperiment)_38_1.png" alt="png"></p>
<p>所以，我们这次课的任务具体地说，则是：</p>
<p><strong>建立一个模型：</strong></p>
<ul>
<li>
<p>输入为一个包含手写文字的图片，尺寸大小是28*28，合计 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>28</mn><mo>×</mo><mn>28</mn><mo>=</mo><mn>784</mn></mrow><annotation encoding="application/x-tex">28\times28=784</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7278em;vertical-align:-0.0833em;"></span><span class="mord">28</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">28</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span></span><span class="base"><span class="strut" style="height:0.6444em;"></span><span class="mord">784</span></span></span></span>个特征。</p>
</li>
<li>
<p>输出为手写文字图片对应的数字。</p>
</li>
</ul>
<h2 id="span-id-4-2-4-2-数据的预处理-span"><span id="4.2">4.2 数据的预处理</span></h2>
<ol>
<li>
<p>扁平化：使二维数组（矩阵）一维化（向量）以便于处理数据</p>
</li>
<li>
<p>二值化：使元素取值取0或255，设定一个阈值，大于此阈值的元素取255，小于此阈值的元素取0。</p>
</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据扁平化</span></span><br><span class="line">dataLen=<span class="built_in">len</span>(hand_written_digits[<span class="number">0</span>])</span><br><span class="line">flattenData=np.reshape(hand_written_digits[<span class="number">0</span>],(dataLen,<span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line"></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;二值化：使元素取值取0或255</span></span><br><span class="line"><span class="string">设定一个阈值，大于此阈值的元素取255，小于此阈值的元素取0&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">binarization</span>(<span class="params">data,threshold</span>):</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> data:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(i)):</span><br><span class="line">            <span class="keyword">if</span> i[j]&gt;=threshold:</span><br><span class="line">                i[j]=<span class="number">255</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                i[j]=<span class="number">0</span></span><br><span class="line">    <span class="keyword">return</span> data  </span><br><span class="line"></span><br><span class="line">flattenData=binarization(flattenData,<span class="number">100</span>)</span><br><span class="line"><span class="comment"># 扁平化后的数据集shape</span></span><br><span class="line"><span class="built_in">print</span>(flattenData.shape)</span><br><span class="line"><span class="built_in">print</span>(hand_written_digits[<span class="number">0</span>].shape)</span><br></pre></td></tr></table></figure>
<pre><code>(12000, 784)
(12000, 28, 28)
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#数据可视化(Heatmap)</span></span><br><span class="line"><span class="comment">#二值化后的Heatmap</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#随机选取5个样本进行展示</span></span><br><span class="line">indexs=np.random.randint(<span class="number">200</span>,size=<span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">8</span>))  </span><br><span class="line">i=<span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> index <span class="keyword">in</span> indexs:</span><br><span class="line">    ax=plt.subplot(<span class="number">1</span>,<span class="built_in">len</span>(indexs),i+<span class="number">1</span>)</span><br><span class="line">    ax.matshow(hand_written_digits[<span class="number">0</span>][index])</span><br><span class="line">    ax.set_title(<span class="string">&quot;Heatmap of %d\n&quot;</span>%(hand_written_digits[<span class="number">1</span>][index]))</span><br><span class="line">    i+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line">plt.show() </span><br></pre></td></tr></table></figure>
<p><img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/RandomForest(ForExperiment)_42_0.png" alt="png"></p>
<center><font size=4 color="red">可以看出，经过二值化的样本的热图不再有渐变色，因为每个像素点的取值非0即255。</font></center>
<h1><span id="5">5. 随机森林</span></h1>
<p>在机器学习中，随机森林是一个包含多个决策树的分类器，并且其输出的类别是由个别树输出的类别的众数而定。 Leo Breiman和Adele Cutler发展出推论出随机森林的算法。</p>
<p>随机森林就是通过集成学习的思想将多棵树集成的一种算法，它的基本单元是决策树，而它的本质属于机器学习的一大分支——集成学习（Ensemble Learning）方法。</p>
<h3 id="随机森林可以看作是决策树的组合">随机森林可以看作是决策树的组合</h3>
<ol>
<li>树的数量的影响（训练时间、欠拟合/过拟合）</li>
<li>随机抽取样本进行决策树的构造</li>
<li>随机抽取特征进行决策树的构造</li>
</ol>
<h3 id="随机森林的随机性">随机森林的随机性</h3>
<ul>
<li>样本的随机性</li>
</ul>
<p>如果训练集大小为N，对于每棵树而言，随机且有放回地从训练集中的抽取N个训练样本，作为该树的训练集。（询问家人、朋友的意见时，每个人以前去过的旅游地是不一样的，所以训练集是不同的。这其实是bagging。）</p>
<ul>
<li>特征的随机性</li>
</ul>
<p>如果每个样本的特征维度为M，指定一个常数m&lt;&lt;M，随机地从M个特征中选取m个特征子集，每次树进行分裂时，从这m个特征中选择最优的。（询问家人、朋友的意见时，每个人考虑的要素是不同的，有人考虑价格，有人考虑交通，所以特征的选取是不同的）</p>
<h3 id="数据集的划分">数据集的划分</h3>
<p><strong>随机森林是一种监督学习的算法，所以我们要对数据集进行划分：将其划分为训练集和测试集</strong></p>
<h3 id="span-id-HW3-作业3：-span"><span id='HW3'>作业3：</span></h3>
<p>复习sklearn.model_selection.train_test_split函数并将hand_written_digits进行数据集划分，测试集大小为数据集的四分之一<br>
<br><strong>注：hand_written_digits[0]为数据集X，hand_written_digits[1]为标签集y。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#划分数据集</span></span><br><span class="line"><span class="keyword">from</span> sklearn.model_selection <span class="keyword">import</span> train_test_split</span><br><span class="line">X_train, X_test, y_train, y_test = train_test_split(hand_written_digits[<span class="number">0</span>], hand_written_digits[<span class="number">1</span>], test_size=<span class="number">0.25</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#使数据集中样本数据扁平化</span></span><br><span class="line">X_train=np.reshape(X_train,(<span class="number">9000</span>,<span class="number">28</span>*<span class="number">28</span>))</span><br><span class="line">X_test=np.reshape(X_test,(<span class="number">3000</span>,<span class="number">28</span>*<span class="number">28</span>))</span><br></pre></td></tr></table></figure>
<h2 id="span-id-5-1-5-1-分类式随机森林-span"><span id="5.1">5.1 分类式随机森林</span></h2>
<p>分类式随机森林由多棵分类决策树构成。</p>
<img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/racoon.png" style="zoom:80%">
<center><font size=4 color=blue>一个分类式随机森林的例子</font><center>
<br/><font size=3>
    图注：
    每棵树是一颗分类决策树，对输入给出自己的结果，最后综合所有决策树的结果给出随机森林的结果。
</font>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#样例：随机森林及其参数</span></span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestClassifier</span><br><span class="line"></span><br><span class="line">rfc_example = RandomForestClassifier(n_estimators=<span class="number">10</span>, criterion=<span class="string">&#x27;gini&#x27;</span>, max_depth=<span class="literal">None</span>,</span><br><span class="line">                                     min_samples_split=<span class="number">2</span>, min_samples_leaf=<span class="number">1</span>, min_weight_fraction_leaf=<span class="number">0.0</span>,</span><br><span class="line">                                     max_features=<span class="string">&#x27;auto&#x27;</span>, max_leaf_nodes=<span class="literal">None</span>, min_impurity_split=<span class="number">1e-07</span>,</span><br><span class="line">                                     bootstrap=<span class="literal">True</span>, oob_score=<span class="literal">False</span>, n_jobs=<span class="number">1</span>, random_state=<span class="literal">None</span>, </span><br><span class="line">                                     verbose=<span class="number">0</span>,warm_start=<span class="literal">False</span>, class_weight=<span class="literal">None</span>)</span><br></pre></td></tr></table></figure>
<h3 id="span-id-rfc-Sklearn分类式随机森林函数中的参数-span"><span id='rfc'>Sklearn分类式随机森林函数中的参数</span></h3>
<ol>
<li>
<p>criterion: ”gini” or “entropy”(default=”gini”)是计算属性的gini(基尼指数)还是entropy(信息增益)，来选择最合适的节点。</p>
</li>
<li>
<p>max_depth: (default=None)设置树的最大深度，默认为None，这样建树时，会使每一个叶节点只有一个类别，或是达到min_samples_split。</p>
</li>
<li>
<p>min_samples_split: 根据属性划分节点时，每个划分最少的样本数。</p>
</li>
<li>
<p>n_estimators: 决策树的个数。</p>
</li>
<li>
<p>oob_score=False：oob（out of bag，袋外）数据，即：在某次决策树训练中没有被bootstrap选中的数据。</p>
</li>
<li>
<p>n_jobs=1：并行job个数。可通过并行提高性能。(n_job=-1时，有多少个core就可以启动多少个job)</p>
</li>
</ol>
<h3 id="将问题视为分类问题：">将问题视为分类问题：</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#构造随机森林（默认参数，使用n_jobs=-1来加速训练速度）</span></span><br><span class="line"></span><br><span class="line">rfc = RandomForestClassifier(n_jobs=-<span class="number">1</span>)</span><br><span class="line">rfc.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Score = &quot;</span>,rfc.score(X_test, y_test))</span><br></pre></td></tr></table></figure>
<pre><code>Score =  0.948
</code></pre>
<h3 id="超参数对模型性能的影响">超参数对模型性能的影响</h3>
<ul>
<li>过拟合：</li>
</ul>
<p>模型过于复杂会导致过拟合，表现为在训练集上的得分较高，但是泛化能力差，在测试集上的得分较低。</p>
<p>在本问题中，max_depth过大或n_estimator过大会导致过拟合。</p>
<ul>
<li>欠拟合：</li>
</ul>
<p>模型过于简单会导致欠拟合，表现为在训练集上和在测试集上得分都较低。</p>
<p>在本问题中，max_depth过大或n_estimator过低会导致过拟合。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">sns.set_style(<span class="string">&quot;whitegrid&quot;</span>)</span><br><span class="line"><span class="comment">#观察决策树数目对模型accuracy的影响</span></span><br><span class="line">x=np.linspace(<span class="number">20</span>,<span class="number">200</span>,<span class="number">30</span>)</span><br><span class="line">y=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> np.linspace(<span class="number">20</span>,<span class="number">200</span>,<span class="number">30</span>):</span><br><span class="line">    rfc_i = RandomForestClassifier(n_estimators=<span class="built_in">int</span>(i+<span class="number">0.5</span>),n_jobs=-<span class="number">1</span>)</span><br><span class="line">    rfc_i.fit(X_train, y_train)</span><br><span class="line">    y.append(rfc_i.score(X_test, y_test))</span><br><span class="line"><span class="comment">#画图观察performance-n_estimators关系</span></span><br><span class="line">plt.plot(x,y,c=<span class="string">&quot;g&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;The relationship between performance and n_estimators&quot;</span>,fontsize=<span class="string">&#x27;xx-large&#x27;</span>,fontweight=<span class="string">&#x27;heavy&#x27;</span>,color=<span class="string">&quot;green&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;n_estimators&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Test Score&quot;</span>)</span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/RandomForest(ForExperiment)_56_0.png" alt="png"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#观察决策树最大深度对模型accuracy的影响</span></span><br><span class="line">x=np.linspace(<span class="number">2</span>,<span class="number">29</span>,<span class="number">28</span>)</span><br><span class="line">y=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>,<span class="number">30</span>):</span><br><span class="line">    rfc_i = RandomForestClassifier(max_depth=i,n_jobs=-<span class="number">1</span>)</span><br><span class="line">    rfc_i.fit(X_train, y_train)</span><br><span class="line">    y.append(rfc_i.score(X_test,y_test))</span><br><span class="line">plt.plot(x,y,c=<span class="string">&quot;r&quot;</span>)</span><br><span class="line">plt.title(<span class="string">&quot;The relationship between performance and max_depth&quot;</span>,fontsize=<span class="string">&#x27;xx-large&#x27;</span>,fontweight=<span class="string">&#x27;heavy&#x27;</span>,color=<span class="string">&quot;red&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="string">&quot;max_depth&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="string">&quot;Test Score&quot;</span>)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<p><img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/RandomForest(ForExperiment)_57_0.png" alt="png"></p>
<p><strong>可以看出，在本问题中，所选择的两个参数取值过小会导致欠拟合，但取值较大时并不容易产生过拟合（随着参数取值的不断增大，模型性能没有减弱）。</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#rfct为最终选择的随机森林模型</span></span><br><span class="line">rfct = RandomForestClassifier(n_estimators=<span class="number">100</span>,max_depth=<span class="number">25</span>)</span><br><span class="line">rfct.fit(X_train, y_train)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试分数 = &quot;</span>,rfct.score(X_test, y_test))</span><br><span class="line"><span class="comment">#用一个list存放被错误分类的数据信息</span></span><br><span class="line">w=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_test)):</span><br><span class="line">    pred=rfct.predict(X_test[i].reshape(<span class="number">1</span>,-<span class="number">1</span>))[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">if</span> pred!=y_test[i]:</span><br><span class="line">        w.append([X_test[i],pred,y_test[i]])</span><br></pre></td></tr></table></figure>
<pre><code>测试分数 =  0.9476666666666667
</code></pre>
<h3 id="分类式随机森林决策过程：">分类式随机森林决策过程：</h3>
<h3 id="span-id-HW4-作业4-span-："><span id='HW4'>作业4</span>：</h3>
<p>观察统计随机森林中所有决策树对某一个样本预测的结果。绘制柱状图。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 补充该cell。</span></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>,<span class="number">5</span>))</span><br><span class="line"><span class="comment">#调取随机森林模型的estimators_数据成员以获取随机森林中决策树们的信息</span></span><br><span class="line">Estimators = rfct.estimators_</span><br><span class="line"></span><br><span class="line">x=np.arange(<span class="number">0</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#此处以数组y来统计vote结果。</span></span><br><span class="line">y=np.zeros(<span class="number">10</span>,dtype=<span class="string">&quot;int&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#随机选取一个样本</span></span><br><span class="line">random_index=random.randint(<span class="number">0</span>,<span class="number">200</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#补充此处：统计所有决策树对X_test[random_index]给出的结果</span></span><br><span class="line"><span class="comment">#提示：使用enumerate, 获取模型对样本的预测可以使用int(model.predict(X_test[random_index].reshape(1,-1))[0])。</span></span><br><span class="line"><span class="keyword">for</span> estimator <span class="keyword">in</span> Estimators:</span><br><span class="line">    y[<span class="built_in">int</span>(estimator.predict(X_test[random_index].reshape(<span class="number">1</span>,-<span class="number">1</span>))[<span class="number">0</span>])]+=<span class="number">1</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#补充此处：绘制统计结果的柱状图，X轴为标签0～9，Y轴为投票结果。</span></span><br><span class="line"><span class="comment">#提示：使用sns.barplot()函数。</span></span><br><span class="line">sns.barplot(x=x,y=y)</span><br><span class="line">plt.show()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;正确答案是: &quot;</span>,y_test[random_index])</span><br></pre></td></tr></table></figure>
<p><img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/RandomForest(ForExperiment)_62_0.png" alt="png"></p>
<pre><code>正确答案是:  8
</code></pre>
<p>分类式随机森林中的每个决策树都得出结果后，所有决策树会进行一次<strong>majority vote</strong>。每个决策树为自己所得的结果投票， <strong><font size=4>得票最多的结果</font></strong> 就是随机森林得到的结果。上图中votes为每个可能结果所得的票数。</p>
<h2 id="span-id-5-2-5-2-回归式随机森林-span"><span id="5.2">5.2 回归式随机森林</span></h2>
<p>回归式随机森林由多棵回归决策树构成。</p>
<h3 id="让我们先来看看sklearn的回归式随机森林函数">让我们先来看看sklearn的回归式随机森林函数</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">sns.set_style(<span class="string">&#x27;white&#x27;</span>)</span><br><span class="line"><span class="keyword">from</span> sklearn.ensemble <span class="keyword">import</span> RandomForestRegressor</span><br><span class="line"></span><br><span class="line">rfr_example=RandomForestRegressor(n_estimators=<span class="number">10</span>, criterion=<span class="string">&#x27;mse&#x27;</span>, </span><br><span class="line">                                             max_depth=<span class="literal">None</span>, min_samples_split=<span class="number">2</span>, </span><br><span class="line">                                             min_samples_leaf=<span class="number">1</span>, min_weight_fraction_leaf=<span class="number">0.0</span>,</span><br><span class="line">                                             max_features=<span class="string">&#x27;auto&#x27;</span>, max_leaf_nodes=<span class="literal">None</span>, </span><br><span class="line">                                             bootstrap=<span class="literal">True</span>, oob_score=<span class="literal">False</span>, </span><br><span class="line">                                             n_jobs=<span class="number">1</span>, random_state=<span class="literal">None</span>, </span><br><span class="line">                                             verbose=<span class="number">0</span>, warm_start=<span class="literal">False</span>)</span><br></pre></td></tr></table></figure>
<h4 id="和分类式随机森林函数区别不大。">和<a href="#rfc">分类式随机森林函数</a>区别不大。</h4>
<h3 id="将问题视为回归问题：">将问题视为回归问题：</h3>
<ol>
<li>最后输出结果会是一个实数，而不是一个分类标签。</li>
<li>汇总各个决策树的预测时可以求平均。</li>
<li>最终的预测结果可以是四舍五入的结果（譬如随机森林给出汇总结果为5.7，则预测为数字6）</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#建立随机森林（回归决策树，默认参数）</span></span><br><span class="line">rfr=RandomForestRegressor(n_jobs=-<span class="number">1</span>)</span><br><span class="line">rfr.fit(X_train,y_train)</span><br><span class="line"><span class="comment">#输出测试分数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练分数:&quot;</span>,rfr.score(X_train,y_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试分数:&quot;</span>,rfr.score(X_test,y_test))</span><br></pre></td></tr></table></figure>
<pre><code>训练分数: 0.976744221955607
测试分数: 0.8295041385895947
</code></pre>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#相同hyperparameter下的回归分类树的效果</span></span><br><span class="line">rfrt=RandomForestRegressor(n_estimators=<span class="number">100</span>,max_depth=<span class="number">25</span>)</span><br><span class="line">rfrt.fit(X_train,y_train)</span><br><span class="line"><span class="comment">#输出测试分数</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;训练分数:&quot;</span>,rfrt.score(X_train,y_train))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;测试分数:&quot;</span>,rfrt.score(X_test,y_test))</span><br><span class="line"></span><br><span class="line"><span class="comment">#用一个list存放被错误分类的数据信息</span></span><br><span class="line">w_r=[]</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(X_test)):</span><br><span class="line">    <span class="comment">#由于使用round函数存在偶尔四舍五入不准的情况，此处使用另一种方法</span></span><br><span class="line">    pred=<span class="built_in">int</span>(rfrt.predict(X_test[i].reshape(<span class="number">1</span>,-<span class="number">1</span>))[<span class="number">0</span>]+<span class="number">0.5</span>)</span><br><span class="line">    <span class="keyword">if</span> pred!=y_test[i]:</span><br><span class="line">        w_r.append([X_test[i],pred,y_test[i]])</span><br></pre></td></tr></table></figure>
<pre><code>训练分数: 0.9762783573500573
测试分数: 0.8278097569753089
</code></pre>
<h2 id="span-id-5-3-5-3-预测错误展示-span"><span id="5.3">5.3 预测错误展示 </span></h2>
<h3 id="让我们观察一下在两种随机森林的分类错误测试样本：">让我们观察一下在两种随机森林的分类错误测试样本：</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#从分类树中选取被错误分类的数据</span></span><br><span class="line"><span class="comment">#分类模型将向量二维化</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(w)):</span><br><span class="line">    w[i][<span class="number">0</span>]=w[i][<span class="number">0</span>].reshape(<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"><span class="comment">#回归模型将向量二维化</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(w_r)):</span><br><span class="line">    w_r[i][<span class="number">0</span>]=w_r[i][<span class="number">0</span>].reshape(<span class="number">28</span>,<span class="number">28</span>)</span><br></pre></td></tr></table></figure>
<h3 id="首先是分类模型的预测错误">首先是分类模型的预测错误</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;错误分类(分类模型)：\n&quot;</span>)</span><br><span class="line">wc=[]</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#选择数字0～9样本各一个进行展示</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span> (<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(w)):</span><br><span class="line">        <span class="keyword">if</span> w[j][<span class="number">2</span>]== i:</span><br><span class="line">            wc.append(w[j])</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#输出预测错误</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(wc)):</span><br><span class="line">    ax=plt.subplot(<span class="number">2</span>,<span class="number">5</span>,i+<span class="number">1</span>) </span><br><span class="line">    ax.matshow(wc[i][<span class="number">0</span>])</span><br><span class="line">    ax.set_title(<span class="string">&quot;Prediction: %(predict)d, Label: %(label)d\n&quot;</span>%&#123;<span class="string">&quot;predict&quot;</span>:wc[i][<span class="number">1</span>],<span class="string">&quot;label&quot;</span>:wc[i][<span class="number">2</span>]&#125;)</span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n预测错误总数量: &quot;</span>,<span class="built_in">len</span>(w))</span><br></pre></td></tr></table></figure>
<pre><code>错误分类(分类模型)：
</code></pre>
<p><img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/RandomForest(ForExperiment)_75_1.png" alt="png"></p>
<pre><code>预测错误总数量:  157
</code></pre>
<h3 id="其次是回归模型的预测错误">其次是回归模型的预测错误</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;错误分类(回归模型)：\n&quot;</span>)</span><br><span class="line">w_rc=[]</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">8</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#选择数字为0～9样本各一个进行展示</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span> (<span class="number">10</span>):</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(w_r)):</span><br><span class="line">        <span class="keyword">if</span> w_r[j][<span class="number">2</span>]== i:</span><br><span class="line">            w_rc.append(w_r[j])</span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#输出预测错误</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="built_in">len</span>(w_rc)):</span><br><span class="line">    ax=plt.subplot(<span class="number">2</span>,<span class="number">5</span>,i+<span class="number">1</span>) </span><br><span class="line">    ax.matshow(w_rc[i][<span class="number">0</span>])</span><br><span class="line">    ax.set_title(<span class="string">&quot;Prediction: %(predict)d, Label: %(label)d\n&quot;</span>%&#123;<span class="string">&quot;predict&quot;</span>:w_rc[i][<span class="number">1</span>],<span class="string">&quot;label&quot;</span>:w_rc[i][<span class="number">2</span>]&#125;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n预测错误总数量: &quot;</span>,<span class="built_in">len</span>(w_r))</span><br></pre></td></tr></table></figure>
<pre><code>错误分类(回归模型)：
</code></pre>
<p><img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/RandomForest(ForExperiment)_77_1.png" alt="png"></p>
<pre><code>预测错误总数量:  1149
</code></pre>
<h1><span id="6">6. 非数据库图片测试</span></h1>
<p><font size=4>使用下面4个手写图片进行预测</font></p>
<p><br/><center><font size=5 color=DodgerBlue>PRESENTED BY: BEILUN WANG</center><br>
<img title="" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/hand_write_3.JPG" alt="" style="zoom:40%"><br>
<br/><center><font size=5 color=DodgerBlue>PRESENTED BY: QIAN WANG</center><br>
<img title="" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/hand_write_4.JPG" alt="" style="zoom:50%"></p>
<center><font size=5 color=DodgerBlue>PRESENTED BY: YAN ZHANG</center>
<img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/hand_write_5.jpg" style="zoom:50%" />
<center><font size=5 color=DodgerBlue>PRESENTED BY: ZHENGXUAN LU</center>
<img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/hand_write_6.jpg" style="zoom:50%" />
<img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/hand_write_7.jpg" style="zoom:40%" />
<center><font size=5 color=DodgerBlue>PRESENTED BY: CHUNSHU LI</center>
<img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/hand_write_8.png" style="zoom:40%" />
<h3 id="非数据库图片预处理">非数据库图片预处理</h3>
<p>图片需要进行预处理使模型可以处理它们。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#运用训练好的模型进行预测</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#使用skimage进行图片读取和预处理</span></span><br><span class="line"><span class="keyword">from</span> skimage <span class="keyword">import</span> io,data,transform    <span class="comment">#skimage: conda install scikit-image</span></span><br><span class="line"><span class="comment">#目标尺寸大小</span></span><br><span class="line">MNIST_SIZE = <span class="number">28</span></span><br><span class="line"><span class="comment">#转换函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">translate</span>(<span class="params">image_path</span>):</span><br><span class="line">    <span class="comment">#读入图片并变成灰度图</span></span><br><span class="line">    img = io.imread(image_path, as_gray=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment">#缩小到28*28 灰度取值范围为[0,255]</span></span><br><span class="line">    translated_img = (<span class="number">1</span>-transform.resize(img, (MNIST_SIZE, MNIST_SIZE)))*<span class="number">1000</span></span><br><span class="line">    <span class="keyword">return</span> translated_img</span><br></pre></td></tr></table></figure>
<h3 id="非数据库图片预测">非数据库图片预测</h3>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;非数据库图片预测&quot;</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">15</span>,<span class="number">10</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#每次预测图片前，需要对图片进行二值化</span></span><br><span class="line"><span class="comment">#PRESENTED BY: YAN ZHANG</span></span><br><span class="line">hand_write_5=binarization(translate(<span class="string">&quot;hand_write_5.jpg&quot;</span>),<span class="number">30</span>)</span><br><span class="line">ax=plt.subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">1</span>)</span><br><span class="line">ax.matshow(hand_write_5)</span><br><span class="line">ax.set_title(<span class="string">&quot;Prediction: %(predict)d, Label: %(label)d\n&quot;</span>%&#123;<span class="string">&quot;predict&quot;</span>:rfct.predict(hand_write_5.reshape(<span class="number">1</span>,-<span class="number">1</span>)),<span class="string">&quot;label&quot;</span>:<span class="number">5</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">#PRESENTED BY YI ZHUANG</span></span><br><span class="line"><span class="comment">#已知输出易得1</span></span><br><span class="line"><span class="comment">#错误的预处理样例</span></span><br><span class="line">hand_write_6=binarization(translate(<span class="string">&quot;hand_write_6.jpg&quot;</span>),<span class="number">128</span>)</span><br><span class="line">ax=plt.subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">2</span>)</span><br><span class="line">ax.matshow(hand_write_6)</span><br><span class="line">ax.set_title(<span class="string">&quot;Prediction: %(predict)d, Label: %(label)d\n&quot;</span>%&#123;<span class="string">&quot;predict&quot;</span>:rfct.predict(hand_write_6.reshape(<span class="number">1</span>,-<span class="number">1</span>)),<span class="string">&quot;label&quot;</span>:<span class="number">6</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">#PRESENTED BY ZHENGXUAN LU</span></span><br><span class="line">hand_write_7=binarization(translate(<span class="string">&quot;hand_write_7.jpg&quot;</span>),<span class="number">80</span>)</span><br><span class="line">ax=plt.subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">3</span>)</span><br><span class="line">ax.matshow(hand_write_7)</span><br><span class="line">ax.set_title(<span class="string">&quot;Prediction: %(predict)d, Label: %(label)d\n&quot;</span>%&#123;<span class="string">&quot;predict&quot;</span>:rfct.predict(hand_write_7.reshape(<span class="number">1</span>,-<span class="number">1</span>)),<span class="string">&quot;label&quot;</span>:<span class="number">7</span>&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">#PRESENTED BY CHUNSHU LI</span></span><br><span class="line">hand_write_8=binarization(translate(<span class="string">&quot;hand_write_8.png&quot;</span>),<span class="number">40</span>)</span><br><span class="line">ax=plt.subplot(<span class="number">1</span>,<span class="number">4</span>,<span class="number">4</span>)</span><br><span class="line">ax.matshow(hand_write_8)</span><br><span class="line">ax.set_title(<span class="string">&quot;Prediction: %(predict)d, Label: %(label)d\n&quot;</span>%&#123;<span class="string">&quot;predict&quot;</span>:rfct.predict(hand_write_8.reshape(<span class="number">1</span>,-<span class="number">1</span>)),<span class="string">&quot;label&quot;</span>:<span class="number">8</span>&#125;)</span><br><span class="line"></span><br><span class="line">plt.show()</span><br></pre></td></tr></table></figure>
<pre><code>非数据库图片预测
</code></pre>
<p><img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/RandomForest(ForExperiment)_83_1.png" alt="png"></p>
<center><font size=5 color=red>由于书写习惯等原因，预测和结果差距可能较大。</font></center>
<h3 id="使用摄像头拍摄手写数字进行预测。（不作要求）">使用摄像头拍摄手写数字进行预测。（不作要求）</h3>
<blockquote>
<p>学习VideoCapture函数来调用摄像头<br>
<br>通过摄像头获得手写数字图片，文件名为test.jpg。<br>
<br>尽量将字迹写粗使特征容易被摄像头捕获。</p>
</blockquote>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">cap = cv2.VideoCapture(<span class="number">0</span>)</span><br><span class="line"><span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">    ret, frame = cap.read()</span><br><span class="line">    frame=frame[<span class="built_in">int</span>(((frame.shape[<span class="number">0</span>]/<span class="number">2</span>)-<span class="number">300</span>)):<span class="built_in">int</span>(((frame.shape[<span class="number">0</span>]/<span class="number">2</span>)+<span class="number">300</span>)),</span><br><span class="line">                <span class="built_in">int</span>(((frame.shape[<span class="number">1</span>]/<span class="number">2</span>)-<span class="number">300</span>)):<span class="built_in">int</span>(((frame.shape[<span class="number">1</span>]/<span class="number">2</span>)+<span class="number">300</span>)),<span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">    cv2.namedWindow(<span class="string">&quot;resized&quot;</span>,<span class="number">0</span>);</span><br><span class="line">    cv2.imshow(<span class="string">&quot;resized&quot;</span>, frame)</span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;s&#x27;</span>):</span><br><span class="line">        cv2.imwrite(<span class="string">&quot;test.jpg&quot;</span>, frame)</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">if</span> cv2.waitKey(<span class="number">1</span>) &amp; <span class="number">0xFF</span> == <span class="built_in">ord</span>(<span class="string">&#x27;q&#x27;</span>):</span><br><span class="line">        <span class="keyword">break</span></span><br><span class="line">cap.release()</span><br><span class="line">cv2.destroyAllWindows()</span><br></pre></td></tr></table></figure>
<p><strong>下面提供接口，您可以自己上传手写数字图片进行预测</strong></p>
<p>请您把需要测试的图片存入该教程的目录下。</p>
<p>可以使用的图片列表：</p>
<blockquote>
<p>hand_write_3.jpg<br>
<br>hand_write_4.jpg<br>
<br>hand_write_5.jpg<br>
<br>hand_write_6.jpg<br>
<br>hand_write_7.jpg<br>
<br>hand_write_8.png<br>
<br>hand_write_9.jpg</p>
</blockquote>
<h3 id="span-id-HW5-作业5：-span"><span id='HW5'>作业5：</span></h3>
<p>手写一个数字（画图/iPad/数位板）保存成图片，命名为&quot;学号_姓名.jpg&quot;在下面给出的接口进行测试，结果仅供图一乐。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#实现预测数字的函数，参数是所使用的模型</span></span><br><span class="line"><span class="comment">#需要把所用的图片上传至该项目的目录下</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">predict_number</span>(<span class="params">model</span>):</span><br><span class="line">    <span class="comment">#输入文件名</span></span><br><span class="line">    image_path=<span class="built_in">input</span>(<span class="string">&quot;Please input the name of the picture(需要后缀名,输入q退出): &quot;</span>)</span><br><span class="line">    <span class="keyword">if</span> image_path==<span class="string">&#x27;1&#x27;</span> <span class="keyword">or</span> image_path==<span class="string">&#x27;Q&#x27;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">False</span></span><br><span class="line">    <span class="comment">#输入标签</span></span><br><span class="line">    <span class="keyword">elif</span> os.path.exists(image_path)==<span class="literal">False</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;没有这个文件名！请重新输入！&quot;</span>)</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line">    label=<span class="built_in">int</span>(<span class="built_in">input</span>(<span class="string">&quot;Please input the label of the picture: &quot;</span>))</span><br><span class="line"></span><br><span class="line">    image=plt.imread(image_path)</span><br><span class="line">    plt.title(<span class="string">&quot;The real picture&quot;</span>)</span><br><span class="line">    plt.imshow(image)</span><br><span class="line"></span><br><span class="line">    image=binarization(translate(image_path),<span class="number">80</span>)</span><br><span class="line">    plt.matshow(image)</span><br><span class="line">    plt.title(<span class="string">&quot;Prediction: %(predict)d, Label: %(label)d\n&quot;</span>%&#123;<span class="string">&quot;predict&quot;</span>:model.predict(image.reshape(<span class="number">1</span>,-<span class="number">1</span>)),<span class="string">&quot;label&quot;</span>:label&#125;)</span><br><span class="line">    plt.show()</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">True</span></span><br><span class="line"></span><br><span class="line">sign=<span class="literal">True</span></span><br><span class="line"><span class="keyword">while</span> sign:</span><br><span class="line">    sign=predict_number(model=rfct)</span><br></pre></td></tr></table></figure>
<pre><code>Please input the name of the picture(需要后缀名,输入q退出): 61520611_张公瑞.jpg
Please input the label of the picture: 1
</code></pre>
<p><img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/RandomForest(ForExperiment)_89_1.png" alt="png"></p>
<p><img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/RandomForest(ForExperiment)_89_2.png" alt="png"></p>
<h1><span id="7">7. 总结</span></h1>
<h3 id="在本课中，我们学习了：">在本课中，我们学习了：</h3>
<blockquote>
<ol>
<li>决策树的概念</li>
<li>分类决策树和回归决策树的概念和生成步骤</li>
<li>随机森林的概念，随机森林的生成，超参数对随机森林的影响</li>
<li>随机森林的运用：手写数字的识别</li>
</ol>
</blockquote>
<h2 id="返回目录"><a href="#content">返回目录</a></h2>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:GearyZhang@outlook.com">TideDra</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://tidedra.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ML-exp2/">https://tidedra.github.io/机器学习/ML-exp2/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://TideDra.github.io" target="_blank">泷汐の精神时光屋</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">机器学习</a></div><div class="post_share"><div class="social-share" data-image="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/ML_exp1_cover.jpg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat_reward.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat_reward.jpg" alt="微信打赏"/></a><div class="post-qr-code-desc">微信打赏</div></li><li class="reward-item"><a href="/img/alipay_reward.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay_reward.jpg" alt="支付宝付款"/></a><div class="post-qr-code-desc">支付宝付款</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90/md-recommand/"><img class="prev-cover" src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/md_recommand_cover.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">这么多Markdown编辑器，我最终选择了它~</div></div></a></div><div class="next-post pull-right"><a href="/uncategorized/flappybird/"><img class="next-cover" src="https://img-blog.csdnimg.cn/b7de95d2fbb64bc2a97cac2ea0393082.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">用纯C++代码写一款精美的FlappyBird</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ML-exp1/" title="【机器学习】入门ML？跟着做这几个实验足矣！（一）"><img class="cover" src="https://img.zsaqwq.com/images/2022/03/28/ML_exp1_cover.jpg" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2022-03-28</div><div class="title">【机器学习】入门ML？跟着做这几个实验足矣！（一）</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="https://img.zsaqwq.com/images/2022/03/26/girl.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">TideDra</div><div class="author-info__description">东南大学吴健雄学院在读本科生</div></div><div class="card-info-data is-center"><div class="card-info-data-item"><a href="/archives/"><div class="headline">文章</div><div class="length-num">11</div></a></div><div class="card-info-data-item"><a href="/tags/"><div class="headline">标签</div><div class="length-num">12</div></a></div><div class="card-info-data-item"><a href="/categories/"><div class="headline">分类</div><div class="length-num">6</div></a></div></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/TideDra"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/TideDra" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="mailto:GearyZhang@outlook.com" target="_blank" title="Email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="tencent://message/?uin=718525108&amp;Site=&amp;Menu=yes" target="_blank" title="QQ"><i class="fa-brands fa-qq"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">本站原域名tidedra.top在备案中，暂时使用tidedra.github.io<br />东南大学超算平台上线啦！欢迎点击:<a target="_blank" rel="noopener" href="https://cswu-challenge.github.io/"><input type=button value="东南大学超算平台"></a></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">1.</span> <span class="toc-text">随机森林</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%9C%AC%E8%AF%BE%E7%A8%8B%E9%9C%80%E8%A6%81%E4%BD%BF%E7%94%A8%E7%9A%84module-os-numpy-pandas-tensorflow-2-0-0%E5%8F%8A%E4%BB%A5%E4%B8%8A-matplotlib-sklearn-graphviz-pydotplus-skimage-opencv-seaborn"><span class="toc-number">1.1.</span> <span class="toc-text">本课程需要使用的module: os, numpy, pandas, tensorflow(2.0.0及以上), matplotlib, sklearn, graphviz, pydotplus, skimage, opencv, seaborn.</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">2.</span> <span class="toc-text">目录</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#0-%E8%AF%BE%E7%A8%8B%E6%91%98%E8%A6%81"><span class="toc-number">2.1.</span> <span class="toc-text">0. 课程摘要</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">2.2.</span> <span class="toc-text">1. 决策树</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-%E5%88%86%E7%B1%BB%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">2.3.</span> <span class="toc-text">2. 分类决策树</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E5%9B%9E%E5%BD%92%E5%86%B3%E7%AD%96%E6%A0%91"><span class="toc-number">2.4.</span> <span class="toc-text">3. 回归决策树</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E6%9C%AC%E8%AF%BE%E4%BB%BB%E5%8A%A1%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.5.</span> <span class="toc-text">4. 本课任务介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-MNIST%E4%BB%8B%E7%BB%8D"><span class="toc-number">2.5.1.</span> <span class="toc-text">- 4.1 MNIST介绍</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E6%95%B0%E6%8D%AE%E7%9A%84%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">2.5.2.</span> <span class="toc-text">- 4.2 数据的预处理</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">2.6.</span> <span class="toc-text">5. 随机森林</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E5%88%86%E7%B1%BB%E5%BC%8F%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">2.6.1.</span> <span class="toc-text">- 5.1 分类式随机森林</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E5%9B%9E%E5%BD%92%E5%BC%8F%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97"><span class="toc-number">2.6.2.</span> <span class="toc-text">- 5.2 回归式随机森林</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E9%A2%84%E6%B5%8B%E9%94%99%E8%AF%AF%E5%B1%95%E7%A4%BA"><span class="toc-number">2.6.3.</span> <span class="toc-text">- 5.3 预测错误展示</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E9%9D%9E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9B%BE%E7%89%87%E6%B5%8B%E8%AF%95"><span class="toc-number">2.7.</span> <span class="toc-text">6. 非数据库图片测试</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E6%80%BB%E7%BB%93"><span class="toc-number">2.8.</span> <span class="toc-text">7. 总结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">3.</span> <span class="toc-text">Homework</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A1"><span class="toc-number">3.1.</span> <span class="toc-text">作业1</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A2"><span class="toc-number">3.2.</span> <span class="toc-text">作业2</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A3"><span class="toc-number">3.3.</span> <span class="toc-text">作业3</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A4"><span class="toc-number">3.4.</span> <span class="toc-text">作业4</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BD%9C%E4%B8%9A5"><span class="toc-number">3.5.</span> <span class="toc-text">作业5</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">4.</span> <span class="toc-text">加载library</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A6%96%E5%85%88%E8%AE%A9%E6%88%91%E4%BB%AC%E5%B0%86%E9%9C%80%E8%A6%81%E7%9A%84module%E5%87%86%E5%A4%87%E5%A5%BD%E3%80%82"><span class="toc-number">4.1.</span> <span class="toc-text">首先让我们将需要的module准备好。</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">5.</span> <span class="toc-text">0. 课程摘要</span></a></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">6.</span> <span class="toc-text">1. 决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%A0%91%E7%9A%84%E7%9B%B8%E5%85%B3%E7%9F%A5%E8%AF%86%EF%BC%9A"><span class="toc-number">6.0.1.</span> <span class="toc-text">树的相关知识：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BE%8B%EF%BC%9A%E6%AD%A4%E5%A4%84%E6%88%91%E4%BB%AC%E4%BB%A5iris-dataset%E7%9A%84%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E5%BB%BA%E7%AB%8B%E4%B8%80%E4%B8%AA%E5%86%B3%E7%AD%96%E6%A0%91%E3%80%82"><span class="toc-number">6.0.2.</span> <span class="toc-text">例：此处我们以iris dataset的分类问题建立一个决策树。</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">7.</span> <span class="toc-text">2. 分类决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E6%A0%91%E5%88%86%E6%9E%90%E6%98%AF%E5%BD%93%E9%A2%84%E8%AE%A1%E7%BB%93%E6%9E%9C%E5%8F%AF%E8%83%BD%E4%B8%BA%E7%A6%BB%E6%95%A3%E7%B1%BB%E5%9E%8B%EF%BC%88%E4%BE%8B%E5%A6%82%E4%B8%89%E4%B8%AA%E7%A7%8D%E7%B1%BB%E7%9A%84%E8%8A%B1%EF%BC%8C%E8%BE%93%E8%B5%A2%E7%AD%89%EF%BC%89%E4%BD%BF%E7%94%A8%E7%9A%84%E6%A6%82%E5%BF%B5%E3%80%82"><span class="toc-number">7.0.0.1.</span> <span class="toc-text">分类树分析是当预计结果可能为离散类型（例如三个种类的花，输赢等）使用的概念。</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BE%8B%EF%BC%9A%E4%BB%A5%E4%BD%93%E9%87%8D%E4%B8%8E%E6%82%A3%E5%BF%83%E8%84%8F%E7%97%85%E6%83%85%E5%86%B5%E7%9A%84%E5%85%B3%E7%B3%BB%E4%B8%BA%E4%BE%8B%E6%9D%A5%E8%AF%B4%E6%98%8E%E5%A6%82%E4%BD%95%E7%94%9F%E6%88%90%E5%88%86%E7%B1%BB%E4%BA%8C%E5%8F%89%E6%A0%91%E3%80%82"><span class="toc-number">7.0.1.</span> <span class="toc-text">例：以体重与患心脏病情况的关系为例来说明如何生成分类二叉树。</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#span-id-HW1-%E4%BD%9C%E4%B8%9A1-span-%EF%BC%9A"><span class="toc-number">7.0.2.</span> <span class="toc-text">作业1：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">8.</span> <span class="toc-text">3. 回归决策树</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BE%8B%EF%BC%9A%E8%8D%AF%E7%89%A9%E5%89%82%E9%87%8F"><span class="toc-number">8.0.1.</span> <span class="toc-text">例：药物剂量</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%AD%A4%E8%A7%86%E9%A2%91%E4%B8%AD%E7%9A%84%E9%97%AE%E9%A2%98%E6%98%AF%E4%B8%80%E4%B8%AA%E5%8D%95%E7%89%B9%E5%BE%81%E9%97%AE%E9%A2%98%EF%BC%88Drug-Effective-Drug-Dosage%EF%BC%89%E3%80%82"><span class="toc-number">8.0.1.1.</span> <span class="toc-text">此视频中的问题是一个单特征问题（Drug-Effective - Drug Dosage）。</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">9.</span> <span class="toc-text">4. 本课任务介绍：手写数字识别问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#span-id-4-1-4-1-MNIST%E4%BB%8B%E7%BB%8D-span"><span class="toc-number">9.1.</span> <span class="toc-text">4.1 MNIST介绍</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#span-id-HW2-%E4%BD%9C%E4%B8%9A2%EF%BC%9A-span"><span class="toc-number">9.1.1.</span> <span class="toc-text">作业2：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#span-id-4-2-4-2-%E6%95%B0%E6%8D%AE%E7%9A%84%E9%A2%84%E5%A4%84%E7%90%86-span"><span class="toc-number">9.2.</span> <span class="toc-text">4.2 数据的预处理</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">10.</span> <span class="toc-text">5. 随机森林</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%8F%AF%E4%BB%A5%E7%9C%8B%E4%BD%9C%E6%98%AF%E5%86%B3%E7%AD%96%E6%A0%91%E7%9A%84%E7%BB%84%E5%90%88"><span class="toc-number">10.0.1.</span> <span class="toc-text">随机森林可以看作是决策树的组合</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%9A%84%E9%9A%8F%E6%9C%BA%E6%80%A7"><span class="toc-number">10.0.2.</span> <span class="toc-text">随机森林的随机性</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E7%9A%84%E5%88%92%E5%88%86"><span class="toc-number">10.0.3.</span> <span class="toc-text">数据集的划分</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#span-id-HW3-%E4%BD%9C%E4%B8%9A3%EF%BC%9A-span"><span class="toc-number">10.0.4.</span> <span class="toc-text">作业3：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#span-id-5-1-5-1-%E5%88%86%E7%B1%BB%E5%BC%8F%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97-span"><span class="toc-number">10.1.</span> <span class="toc-text">5.1 分类式随机森林</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#span-id-rfc-Sklearn%E5%88%86%E7%B1%BB%E5%BC%8F%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%87%BD%E6%95%B0%E4%B8%AD%E7%9A%84%E5%8F%82%E6%95%B0-span"><span class="toc-number">10.1.1.</span> <span class="toc-text">Sklearn分类式随机森林函数中的参数</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%86%E9%97%AE%E9%A2%98%E8%A7%86%E4%B8%BA%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%EF%BC%9A"><span class="toc-number">10.1.2.</span> <span class="toc-text">将问题视为分类问题：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%B6%85%E5%8F%82%E6%95%B0%E5%AF%B9%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD%E7%9A%84%E5%BD%B1%E5%93%8D"><span class="toc-number">10.1.3.</span> <span class="toc-text">超参数对模型性能的影响</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E5%BC%8F%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%86%B3%E7%AD%96%E8%BF%87%E7%A8%8B%EF%BC%9A"><span class="toc-number">10.1.4.</span> <span class="toc-text">分类式随机森林决策过程：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#span-id-HW4-%E4%BD%9C%E4%B8%9A4-span-%EF%BC%9A"><span class="toc-number">10.1.5.</span> <span class="toc-text">作业4：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#span-id-5-2-5-2-%E5%9B%9E%E5%BD%92%E5%BC%8F%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97-span"><span class="toc-number">10.2.</span> <span class="toc-text">5.2 回归式随机森林</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A9%E6%88%91%E4%BB%AC%E5%85%88%E6%9D%A5%E7%9C%8B%E7%9C%8Bsklearn%E7%9A%84%E5%9B%9E%E5%BD%92%E5%BC%8F%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%87%BD%E6%95%B0"><span class="toc-number">10.2.1.</span> <span class="toc-text">让我们先来看看sklearn的回归式随机森林函数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%92%8C%E5%88%86%E7%B1%BB%E5%BC%8F%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E5%87%BD%E6%95%B0%E5%8C%BA%E5%88%AB%E4%B8%8D%E5%A4%A7%E3%80%82"><span class="toc-number">10.2.1.1.</span> <span class="toc-text">和分类式随机森林函数区别不大。</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%B0%86%E9%97%AE%E9%A2%98%E8%A7%86%E4%B8%BA%E5%9B%9E%E5%BD%92%E9%97%AE%E9%A2%98%EF%BC%9A"><span class="toc-number">10.2.2.</span> <span class="toc-text">将问题视为回归问题：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#span-id-5-3-5-3-%E9%A2%84%E6%B5%8B%E9%94%99%E8%AF%AF%E5%B1%95%E7%A4%BA-span"><span class="toc-number">10.3.</span> <span class="toc-text">5.3 预测错误展示 </span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AE%A9%E6%88%91%E4%BB%AC%E8%A7%82%E5%AF%9F%E4%B8%80%E4%B8%8B%E5%9C%A8%E4%B8%A4%E7%A7%8D%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97%E7%9A%84%E5%88%86%E7%B1%BB%E9%94%99%E8%AF%AF%E6%B5%8B%E8%AF%95%E6%A0%B7%E6%9C%AC%EF%BC%9A"><span class="toc-number">10.3.1.</span> <span class="toc-text">让我们观察一下在两种随机森林的分类错误测试样本：</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%A6%96%E5%85%88%E6%98%AF%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A2%84%E6%B5%8B%E9%94%99%E8%AF%AF"><span class="toc-number">10.3.2.</span> <span class="toc-text">首先是分类模型的预测错误</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%85%B6%E6%AC%A1%E6%98%AF%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E7%9A%84%E9%A2%84%E6%B5%8B%E9%94%99%E8%AF%AF"><span class="toc-number">10.3.3.</span> <span class="toc-text">其次是回归模型的预测错误</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">11.</span> <span class="toc-text">6. 非数据库图片测试</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9D%9E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9B%BE%E7%89%87%E9%A2%84%E5%A4%84%E7%90%86"><span class="toc-number">11.0.1.</span> <span class="toc-text">非数据库图片预处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9D%9E%E6%95%B0%E6%8D%AE%E5%BA%93%E5%9B%BE%E7%89%87%E9%A2%84%E6%B5%8B"><span class="toc-number">11.0.2.</span> <span class="toc-text">非数据库图片预测</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%BF%E7%94%A8%E6%91%84%E5%83%8F%E5%A4%B4%E6%8B%8D%E6%91%84%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%BF%9B%E8%A1%8C%E9%A2%84%E6%B5%8B%E3%80%82%EF%BC%88%E4%B8%8D%E4%BD%9C%E8%A6%81%E6%B1%82%EF%BC%89"><span class="toc-number">11.0.3.</span> <span class="toc-text">使用摄像头拍摄手写数字进行预测。（不作要求）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#span-id-HW5-%E4%BD%9C%E4%B8%9A5%EF%BC%9A-span"><span class="toc-number">11.0.4.</span> <span class="toc-text">作业5：</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-number">12.</span> <span class="toc-text">7. 总结</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%9C%A8%E6%9C%AC%E8%AF%BE%E4%B8%AD%EF%BC%8C%E6%88%91%E4%BB%AC%E5%AD%A6%E4%B9%A0%E4%BA%86%EF%BC%9A"><span class="toc-number">12.0.1.</span> <span class="toc-text">在本课中，我们学习了：</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BF%94%E5%9B%9E%E7%9B%AE%E5%BD%95"><span class="toc-number">12.1.</span> <span class="toc-text">返回目录</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/uncategorized/flappybird/" title="用纯C++代码写一款精美的FlappyBird"><img src="https://img-blog.csdnimg.cn/b7de95d2fbb64bc2a97cac2ea0393082.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="用纯C++代码写一款精美的FlappyBird"/></a><div class="content"><a class="title" href="/uncategorized/flappybird/" title="用纯C++代码写一款精美的FlappyBird">用纯C++代码写一款精美的FlappyBird</a><time datetime="2022-03-31T14:27:09.000Z" title="发表于 2022-03-31 22:27:09">2022-03-31</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ML-exp2/" title="【机器学习】入门ML？跟着做这几个实验足矣！（二）"><img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/ML_exp1_cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】入门ML？跟着做这几个实验足矣！（二）"/></a><div class="content"><a class="title" href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ML-exp2/" title="【机器学习】入门ML？跟着做这几个实验足矣！（二）">【机器学习】入门ML？跟着做这几个实验足矣！（二）</a><time datetime="2022-03-29T16:59:36.000Z" title="发表于 2022-03-30 00:59:36">2022-03-30</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90/md-recommand/" title="这么多Markdown编辑器，我最终选择了它~"><img src="https://myblog-1308049971.cos.ap-nanjing.myqcloud.com/md_recommand_cover.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="这么多Markdown编辑器，我最终选择了它~"/></a><div class="content"><a class="title" href="/%E8%BD%AF%E4%BB%B6%E6%8E%A8%E8%8D%90/md-recommand/" title="这么多Markdown编辑器，我最终选择了它~">这么多Markdown编辑器，我最终选择了它~</a><time datetime="2022-03-28T13:46:33.000Z" title="发表于 2022-03-28 21:46:33">2022-03-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ML-exp1/" title="【机器学习】入门ML？跟着做这几个实验足矣！（一）"><img src="https://img.zsaqwq.com/images/2022/03/28/ML_exp1_cover.jpg" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【机器学习】入门ML？跟着做这几个实验足矣！（一）"/></a><div class="content"><a class="title" href="/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ML-exp1/" title="【机器学习】入门ML？跟着做这几个实验足矣！（一）">【机器学习】入门ML？跟着做这几个实验足矣！（一）</a><time datetime="2022-03-28T07:48:41.000Z" title="发表于 2022-03-28 15:48:41">2022-03-28</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/VM-performance-test/" title="【操作系统】虚拟机（WSL2）的性能相比真机缩水了多少？"><img src="https://img.zsaqwq.com/images/2022/03/27/wsl2_logo.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【操作系统】虚拟机（WSL2）的性能相比真机缩水了多少？"/></a><div class="content"><a class="title" href="/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/VM-performance-test/" title="【操作系统】虚拟机（WSL2）的性能相比真机缩水了多少？">【操作系统】虚拟机（WSL2）的性能相比真机缩水了多少？</a><time datetime="2022-03-27T07:00:20.000Z" title="发表于 2022-03-27 15:00:20">2022-03-27</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('https://img.zsaqwq.com/images/2022/03/26/footer.png')"><div id="footer-wrap"><div class="copyright">&copy;2022 By TideDra</div><div class="footer_custom_text">Hi, welcome to my <a target="_blank" rel="noopener" href="https://www.tidedra.top/">blog</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="algolia-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">Algolia</span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="search-wrap"><div id="algolia-search-input"></div><hr/><div id="algolia-search-results"><div id="algolia-hits"></div><div id="algolia-pagination"></div><div id="algolia-stats"></div></div></div></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui/dist/fancybox.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script src="https://cdn.jsdelivr.net/npm/algoliasearch@4/dist/algoliasearch-lite.umd.js"></script><script src="https://cdn.jsdelivr.net/npm/instantsearch.js@4/dist/instantsearch.production.min.js"></script><script src="/js/search/algolia.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css"><script src="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.min.js"></script><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/copy-tex.css"><script>(() => {
  document.querySelectorAll('#article-container span.katex-display').forEach(item => {
    btf.wrap(item, 'div', { class: 'katex-wrap'})
  })
})()</script><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'Ma2oIbe5SQqQadapIhXlTNs3-MdYXbMMI',
      appKey: 'QEjKMYAuQqGLtfegLWHkhles',
      avatar: 'monsterid',
      serverURLs: '',
      emojiMaps: "",
      path: window.location.pathname,
      visitor: true
    }, {"meta":["nick","mail"],"requiredFields":["nick","mail"],"serverURLs":"https://ma2oibe5.api.lncldglobal.com"}))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors = ["title","#config-diff","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"]

var pjax = new Pjax({
  elements: 'a:not([target="_blank"])',
  selectors: pjaxSelectors,
  cacheBust: false,
  analytics: false,
  scrollRestoration: false
})

document.addEventListener('pjax:send', function () {

  // removeEventListener scroll 
  window.tocScrollFn && window.removeEventListener('scroll', window.tocScrollFn)
  window.scrollCollect && window.removeEventListener('scroll', scrollCollect)

  typeof preloader === 'object' && preloader.initLoading()
  document.getElementById('rightside').style.cssText = "opacity: ''; transform: ''"
  
  if (window.aplayers) {
    for (let i = 0; i < window.aplayers.length; i++) {
      if (!window.aplayers[i].options.fixed) {
        window.aplayers[i].destroy()
      }
    }
  }

  typeof typed === 'object' && typed.destroy()

  //reset readmode
  const $bodyClassList = document.body.classList
  $bodyClassList.contains('read-mode') && $bodyClassList.remove('read-mode')

})

document.addEventListener('pjax:complete', function () {
  window.refreshFn()

  document.querySelectorAll('script[data-pjax]').forEach(item => {
    const newScript = document.createElement('script')
    const content = item.text || item.textContent || item.innerHTML || ""
    Array.from(item.attributes).forEach(attr => newScript.setAttribute(attr.name, attr.value))
    newScript.appendChild(document.createTextNode(content))
    item.parentNode.replaceChild(newScript, item)
  })

  GLOBAL_CONFIG.islazyload && window.lazyLoadInstance.update()

  typeof chatBtnFn === 'function' && chatBtnFn()
  typeof panguInit === 'function' && panguInit()

  // google analytics
  typeof gtag === 'function' && gtag('config', '', {'page_path': window.location.pathname});

  // baidu analytics
  typeof _hmt === 'object' && _hmt.push(['_trackPageview',window.location.pathname]);

  typeof loadMeting === 'function' && document.getElementsByClassName('aplayer').length && loadMeting()

  // prismjs
  typeof Prism === 'object' && Prism.highlightAll()

  typeof preloader === 'object' && preloader.endLoading()
})

document.addEventListener('pjax:error', (e) => {
  if (e.request.status === 404) {
    pjax.loadUrl('/404.html')
  }
})</script><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>